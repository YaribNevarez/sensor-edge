\title {CNN Sensor Analytics with Hybrid-Float6 Quantization on Low-Power Embedded FPGAs.}

\author{
	\uppercase{Yarib Nevarez}\authorrefmark{1},
	\uppercase{Andreas Beering}\authorrefmark{1},
	\uppercase{Amir Najafi}\authorrefmark{1},
	\uppercase{Ardalan Najafi}\authorrefmark{1},
	\uppercase{Wanli Yu}\authorrefmark{1},
	\uppercase{Yizhi Chen}\authorrefmark{2},
	\uppercase{Karl-Ludwig Krieger}\authorrefmark{1},
	\uppercase{Alberto Garcia-Ortiz}\authorrefmark{1} \IEEEmembership{Member, IEEE},
}

\address[1]{Institute of Electrodynamics and Microelectronics, University of Bremen, Bremen 28359, Germany}

\address[2]{School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, 10044 Stockholm, Sweden}


\tfootnote{This work is funded by the Consejo Nacional de Ciencia y Tecnologia (CONACYT) and the Federal Ministry for Economic Affairs and Climate Action ZIM project IMOP (ZF4176708LP9).}

\markboth
{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}
{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}

\corresp{Corresponding author: Yarib Nevarez (e-mail: nevarez@item.uni-bremen.de).}

\begin{abstract}
The use of artificial intelligence (AI) in sensor analytics is entering a new era based on the use of ubiquitous embedded connected devices. This transformation requires the adoption of design techniques that reconcile accurate results with sustainable system architectures. As such, improving the efficiency of AI hardware engines as well as backward compatibility must be considered. In this paper, we present the Hybrid-Float6 (HF6) quantization and its dedicated hardware design. We propose an optimized multiply-accumulate (MAC) hardware by reducing the mantissa multiplication to a multiplexor-adder operation. We exploit the intrinsic error tolerance of neural networks to further reduce the hardware design with approximation. To preserve model accuracy, we present a quantization-aware training (QAT) method, which in some cases improves accuracy. We demonstrate this concept in 2D convolution layers. We present a lightweight tensor processor (TP) implementing a pipelined vector dot-product. For compatibility and portability, the 6-bit floating-point (FP) is wrapped in the standard FP format, which is automatically extracted by the proposed hardware. The hardware/software architecture is compatible with TensorFlow (TF) Lite. We evaluate the applicability of our approach with a CNN-regression model for anomaly localization in a structural health monitoring (SHM) application based on acoustic emission (AE). The embedded hardware/software framework is demonstrated on XC7Z007S as the smallest Zynq-7000 SoC. The proposed implementation achieves a peak power efficiency and run-time acceleration of $5.7$ GFLOPS/s/W and $48.3\times$, respectively.
\end{abstract}

\begin{keywords}
Convolutional neural networks, structural health monitoring, hardware accelerator, TensorFlow Lite, embedded systems, FPGA, custom floating-point
\end{keywords}

\titlepgskip=-15pt

\maketitle