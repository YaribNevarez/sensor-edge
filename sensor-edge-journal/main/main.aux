\relax 
\citation{lom2016industry}
\citation{li2019sensor,dong2018rolling}
\citation{nagayama2007structural}
\citation{wang2019deep}
\citation{kim2017hazardous}
\citation{ince2016real,janssens2016convolutional,abdeljaber2017real,guo2016hierarchical}
\citation{du2014leveraging}
\citation{nurvitadhi2017can}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}\protected@file@percent }
\newlabel{sec:introduction}{{I}{1}}
\citation{wu2021low}
\citation{han2015deep,han2015learning}
\citation{mei2017200mhz,wu2021low,lian2019high}
\citation{courbariaux2015binaryconnect}
\citation{lin2015neural}
\citation{colangelo2018exploration}
\citation{lai2017deep}
\citation{lai2017deep}
\citation{settle2018quantizing}
\citation{lai2017deep}
\citation{settle2018quantizing}
\citation{lian2019high}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The workflow of our approach on embedded FPGAs.}}{2}\protected@file@percent }
\newlabel{fig:workflow}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related work}{2}\protected@file@percent }
\newlabel{sec:related_work}{{II}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Hybrid Custom Floating-Point}{2}\protected@file@percent }
\citation{mei2017200mhz}
\citation{wu2021low}
\citation{meloni2019cnn}
\citation{gao2020edgedrnn}
\citation{gu2018recent}
\citation{goodfellow2016deep}
\citation{zuras2008ieee}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Low-Precision Floating-Point}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Low-Power}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Background}{3}\protected@file@percent }
\newlabel{sec:background}{{III}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Conv2D tensor operation}{3}\protected@file@percent }
\newlabel{eq:conv2D}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Floating-point Number Representation}{3}\protected@file@percent }
\newlabel{eq:float}{{2}{3}}
\newlabel{eq:float_bias}{{3}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Floating-point number representation.}}{3}\protected@file@percent }
\newlabel{fig:floating}{{2}{3}}
\citation{nevarez2021accelerating}
\newlabel{eq:float_subnorm}{{4}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}System Design}{4}\protected@file@percent }
\newlabel{sec:system_design}{{IV}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Base embedded system architecture}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Tensor processor}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {IV-B}1}{\fontencoding  {T1}\fontseries  {b}\selectfont  {M}odes of operation}}{4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Base embedded system architecture.}}{4}\protected@file@percent }
\newlabel{fig:system_architecture}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Hardware architecture of the proposed tensor processor.}}{4}\protected@file@percent }
\newlabel{fig:accelerator}{{4}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {IV-B}2}{\fontencoding  {T1}\fontseries  {b}\selectfont  {D}ot-product with hybrid floating-point}}{4}\protected@file@percent }
\newlabel{sec:dot_product}{{\mbox  {IV-B}2}{4}}
\citation{du2014leveraging}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Dot-product hardware module with (a) standard floating-point and (b) Hybrid-Float6.}}{5}\protected@file@percent }
\newlabel{fig:dot_product}{{5}{5}}
\newlabel{eq:dot_custom_float_latency}{{5}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Pipelined hardware module for vector dot-product with hybrid custom floating-point, (a) exhibits the initiation interval of 1 clock cycle, and (b) presents the iteration latency of 8 clock cycles. $I_H$ and $I_F$ represent the input and filter buffer indexes, respectively.}}{5}\protected@file@percent }
\newlabel{fig:dot_product_hybrid}{{6}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Design parameters for on-chip memory buffers on the TP.}}{5}\protected@file@percent }
\newlabel{fig:accelerator_buffers}{{7}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {IV-B}3}{\fontencoding  {T1}\fontseries  {b}\selectfont  {O}n-chip memory utilization}}{5}\protected@file@percent }
\newlabel{sec:memory_utilization}{{\mbox  {IV-B}3}{5}}
\newlabel{eq:tp_memory}{{6}{5}}
\newlabel{eq:tp_memory_buffer}{{7}{5}}
\citation{lai2017deep}
\newlabel{eq:input_memory}{{8}{6}}
\newlabel{eq:filter_memory}{{9}{6}}
\newlabel{eq:bias_memory}{{10}{6}}
\newlabel{eq:channel_in_memory}{{11}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-C}}Training Method}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {IV-C}1}Training with Iterative Early Stop}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {IV-C}2}Quantization Aware Training}{6}\protected@file@percent }
\newlabel{alg:training}{{1}{6}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Training with iterative early stop cycle.}}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-D}}Embedded software architecture}{6}\protected@file@percent }
\newlabel{alg:quantization_integration}{{2}{7}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces OnMiniBatchUpdate\_Callback.}}{7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Base embedded software architecture.}}{7}\protected@file@percent }
\newlabel{fig:sw_stack}{{8}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Experimental results}{7}\protected@file@percent }
\newlabel{sec:experimental_results}{{V}{7}}
\newlabel{alg:quantize_training}{{3}{7}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Custom floating-point quantization.}}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Sensor Analytics Application}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-A}1}Experimental Setup}{7}\protected@file@percent }
\citation{hannwindowsine}
\citation{stft_lit}
\citation{blackman_window}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Experimental setup for sensor analytics on structural health monitoring.}}{8}\protected@file@percent }
\newlabel{fig:data_set}{{9}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-A}2}Data Sets}{8}\protected@file@percent }
\newlabel{stft_eq2}{{13}{8}}
\newlabel{stft_eq3}{{14}{8}}
\citation{kingma2014adam}
\citation{hannwindowsine}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Spectrograms of sensors $S_1, S_2$ converted to grayscale for pulses at $x =0.105$, $y = 0.109$ with noise disturbance.}}{9}\protected@file@percent }
\newlabel{fig:spectrograms}{{10}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-A}3}CNN-Regression Model}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Training}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}1}Base Model}{9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces CNN-regression model for sensor analytics.}}{9}\protected@file@percent }
\newlabel{fig:model}{{11}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}2}TensorFlow Lite 8-bit quantization}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}3}Quantization Aware Training for Hybrid-Float6}{9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Training results.}}{10}\protected@file@percent }
\newlabel{fig:optimization}{{12}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}4}Quantization Aware Training for Hybrid-Logarithmic 6-bit}{10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Performance of the model with different data representations.}}{10}\protected@file@percent }
\newlabel{fig:model_evaluation}{{13}{10}}
\citation{xilinx2015zynq}
\citation{hrica2012floating}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Hardware Design Exploration}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-C}1}Benchmark on Embedded CPU}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-C}2}Benchmark on Tensor Processor with Standard Floating-Point Hardware using Xilinx LogiCORE IP}{11}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Resource utilization and power dissipation on the Zynq-7007S SoC.}}{11}\protected@file@percent }
\newlabel{tab:resource_utilization}{{1}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Compute performance of the CPU and TP on each Conv2D tensor operation. This table presents: tensor operation, computational cost in mega floating-point operations (MFLOP), latency, throughput, power efficiency, and estimated energy consumption as the energy delay product (EDP).}}{11}\protected@file@percent }
\newlabel{tab:performance}{{2}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Inference acceleration and power reduction on the TP with floating-point and HF6 vs. CPU on the Zynq-7007S SoC.}}{11}\protected@file@percent }
\newlabel{fig:acceleration}{{14}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Resource utilization and power dissipation of multiplier and adder floating-point (IEEE 754) operator cores (Xilinx LogiCORE IP).}}{11}\protected@file@percent }
\newlabel{tab:LogiCORE}{{3}{11}}
\citation{springenberg2014striving}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-C}3}Tensor Processor with Hybrid-Float6 Hardware}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-D}}Discussion}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-D}1}Training and Quantization}{12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Run-time inference of TensorFlow Lite on the Zynq-7007S SoC. (a) CPU ARM Cortex-A9 at 666MHz, (b) cooperative CPU + TP with floating-point Xilinx LogiCORE IP at 200MHz, and (c) cooperative CPU + TP with Hybrid-Float6 at 200MHz.}}{12}\protected@file@percent }
\newlabel{fig:runtime}{{15}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-D}2}Implementation and Performance}{12}\protected@file@percent }
\citation{mei2017200mhz}
\citation{wu2021low}
\citation{lian2019high}
\citation{meloni2019cnn}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces 2D error distribution of three CNN-regression models.}}{13}\protected@file@percent }
\newlabel{fig:2d_error_distribtion}{{16}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Hardware resource utilization on the Zynq-7007S SoC.}}{13}\protected@file@percent }
\newlabel{fig:resource_utilization}{{17}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Estimated power dissipation on the Zynq-7007S SoC with PS at 666MHz and PL at 200MHz.}}{13}\protected@file@percent }
\newlabel{fig:power}{{18}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-D}3}SoC Design and Compatibility}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-D}4}Future Work}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusions}{13}\protected@file@percent }
\newlabel{sec:conclusions}{{VI}{13}}
\bibstyle{IEEEtran}
\bibdata{../content/bibliography.bib}
\bibcite{lom2016industry}{1}
\bibcite{li2019sensor}{2}
\bibcite{dong2018rolling}{3}
\bibcite{nagayama2007structural}{4}
\bibcite{wang2019deep}{5}
\bibcite{kim2017hazardous}{6}
\bibcite{ince2016real}{7}
\bibcite{janssens2016convolutional}{8}
\bibcite{abdeljaber2017real}{9}
\bibcite{guo2016hierarchical}{10}
\bibcite{nurvitadhi2017can}{11}
\bibcite{wu2021low}{12}
\bibcite{han2015deep}{13}
\bibcite{han2015learning}{14}
\bibcite{mei2017200mhz}{15}
\bibcite{lian2019high}{16}
\bibcite{courbariaux2015binaryconnect}{17}
\bibcite{lin2015neural}{18}
\bibcite{colangelo2018exploration}{19}
\bibcite{lai2017deep}{20}
\bibcite{settle2018quantizing}{21}
\bibcite{meloni2019cnn}{22}
\bibcite{gao2020edgedrnn}{23}
\bibcite{gu2018recent}{24}
\bibcite{goodfellow2016deep}{25}
\bibcite{zuras2008ieee}{26}
\bibcite{nevarez2021accelerating}{27}
\bibcite{du2014leveraging}{28}
\bibcite{hannwindowsine}{29}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Comparison of hardware implementation with related work.}}{14}\protected@file@percent }
\newlabel{tab:comparison}{{4}{14}}
\@writefile{toc}{\contentsline {section}{REFERENCES}{14}\protected@file@percent }
\bibcite{stft_lit}{30}
\bibcite{blackman_window}{31}
\bibcite{kingma2014adam}{32}
\bibcite{xilinx2015zynq}{33}
\bibcite{hrica2012floating}{34}
\bibcite{springenberg2014striving}{35}
